# üß¨ Classifica√ß√£o de Subtipos de C√¢ncer de Mama com Ensemble Learning
Este reposit√≥rio cont√©m o c√≥digo-fonte e a metodologia do trabalho que prop√µe a utiliza√ß√£o do Ensemble Learning para a classifica√ß√£o aprimorada de subtipos de c√¢ncer de mama, superando desafios comuns como dados transcript√¥micos limitados e incompletos.

‚û°Ô∏è**Artigo Completo (PDF):** [Acesse o Artigo Aceito no Congresso Pan-Amaz√¥nico de Oncologia](https://github.com/gabrielqueeiroz/breast-cancer-ensemble-learning/blob/main/gabriel-pan-amazonico1.pdf) <br>
‚û°Ô∏è**Poster Apresentado:** [Visualize o Poster](https://github.com/gabrielqueeiroz/breast-cancer-ensemble-learning/blob/main/Poster-Pan-Amazonico-2.pdf)

## üí° O problema: Limita√ß√£o e Inconsist√™ncia nos Dados
A classifica√ß√£o molecular do c√¢ncer de mama √© crucial para o tratamento eficaz. No entanto, os dados de express√£o g√™nica utilizados apresentam barreiras significativas:
* **Dados Incompletos:** Os dados obtidos via microarrays podem conter valores perdidos ("omissos") devido a fatores t√©cnicos, como poeira nas l√¢minas.
* **Dataset Limitado:** O conjunto de dados de 117 amostras (derivado do CPTAC e filtrado pelo PAM50) √© considerado pequeno para t√©cnicas avan√ßadas.
* **Dificuldade de Distin√ß√£o:** Classificadores individuais, como o Support Vector Classifier (SVC), apresentam consider√°vel dificuldade em distinguir classes moleculares intimamente relacionadas, como Luminal A (LumA) e Luminal B (LumB).
  
## üõ†Ô∏è Nossa Solu√ß√£o:
Para mitigar o risco de sobreajuste (overfitting) e aumentar a capacidade de generaliza√ß√£o em datasets pequenos , propusemos um modelo de Aprendizado em Comit√™ (Ensemble Learning) baseado em vota√ß√£o.

A solu√ß√£o utiliza o **VotingClassifier**, combinando as previs√µes de diferentes modelos para uma decis√£o final, sendo eles:
* Support Vector Classifier (SVC)
* Random Forest Classifier (RF)
* Gradient Boosting Classifier (GB)
* Logistic Regression (LR)

**Estrat√©gia Otimizada:** Foi utilizada a modalidade Soft Voting, que calcula a m√©dia das probabilidades de previs√£o de cada modelo, permitindo que classificadores com maior confian√ßa influenciem mais a decis√£o final.

## ‚ú® Contribui√ß√£o Principal e Resultados
O modelo de ensemble superou significativamente o desempenho dos classificadores individuais, validando a hip√≥tese de que a diversidade de modelos √© crucial para otimizar a classifica√ß√£o em cen√°rios desafiadores.

## Tabela 2 - Resultados da classifica√ß√£o com classificadores individuais e ensemble

| M√©trica | Random Forest | Gradient Boosting | Logistic Regression | Support Vector Classification | Voting soft + GB | Voting soft | Voting hard + GB | Voting hard |
| :--- | :--- | :--- | :--- | :--- | :---: | :--- | :--- | :--- |
| Acur√°cia | 0.932 | 0.829 | 0.889 | 0.906 | **0.966** | 0.914 | 0.922 | 0.906 |
| Precis√£o | 0.873 | 0.778 | 0.890 | 0.917 | **0.957** | 0.900 | 0.880 | 0.896 |
| Recall | 0.917 | 0.791 | 0.913 | 0.891 | **0.976** | 0.910 | 0.949 | 0.901 |
| F1-Score | 0.885 | 0.760 | 0.875 | 0.891 | **0.960** | 0.894 | 0.897 | 0.885 |

*Obs: O melhor resultado foi obtido pelo Soft Voting com Gradient Boosting.*

A superioridade do Soft Voting demonstrou efic√°cia em:
* **Corre√ß√£o de Erros:** O comit√™ conseguiu acertar inst√¢ncias de fronteira que os modelos isolados classificaram erroneamente.
* **Resolu√ß√£o de Confus√£o:** O ensemble resolveu as dificuldades na classifica√ß√£o entre as classes Luminal A e Luminal B, generalizando de forma eficaz para todas as classes.
